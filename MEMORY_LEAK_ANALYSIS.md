# üîç Why Your Server Runs Out of RAM - Root Cause Analysis

## üìä Current System Status

**Good news:** Your system currently has:
- **Total RAM**: 7.8GB
- **Used**: 2.1GB  
- **Available**: 5.7GB
- **Next.js server**: Using ~137MB (reasonable)

**The problem:** At certain times, memory usage **spikes dramatically**, causing the OOM (Out Of Memory) killer to terminate your process.

---

## üî¥ Root Causes Identified

### 1. **Duplicate Schema Index Warning (Memory Leak)**

**From your error log (Line 27):**
```
(node:24913) [MONGOOSE] Warning: Duplicate schema index on {"domainName":1}
```

**What's happening:**
- In `models/PendingDomain.ts`, line 38: `unique: true` creates an index
- Lines 144-147: Additional indexes are created
- **Every time the model is imported**, Mongoose tries to create these indexes again
- This creates duplicate index definitions that accumulate in memory

**The Problem:**
```typescript
// Line 38 - Creates index automatically
domainName: {
  unique: true,  // <-- Creates domainName_1 index
}

// Lines 144-147 - Comment says it's automatic, but...
// Note: domainName index is automatically created by unique: true
PendingDomainSchema.index({ userId: 1, status: 1 });
PendingDomainSchema.index({ orderId: 1 });
```

**Impact:** Each API request that imports this model adds more index definitions to memory.

---

### 2. **Unbounded Database Queries Loading Too Much Data**

**Found in your code:**

#### A. Admin Orders Route (`app/api/admin/orders/route.ts`)
```typescript
const orders = await Order.find(query)
  .sort({ createdAt: -1 })
  .limit(100) // Limit to last 100 orders
  .populate("userId", "firstName lastName email", User);
```
- Loads 100 orders with full user data
- Each order can have multiple domains with booking status arrays
- **Memory per query**: ~5-20MB depending on order complexity

#### B. Admin Pending Domains (`app/api/admin/pending-domains/route.ts`)
```typescript
// STEP 1: Get ALL pending domains from collection
const pendingDomainsFromCollection = await PendingDomain.find(filters)
  .sort(sortOptions)
  .populate("userId", "firstName lastName email", User); // NO LIMIT!

// STEP 2: Get ALL orders with pending/processing domains  
const ordersWithPendingDomains = await Order.find({
  "domains.status": { $in: ["pending", "processing"] },
  isDeleted: { $ne: true },
})
  .populate("userId", "firstName lastName email", User)
  .sort({ createdAt: -1 }); // NO LIMIT!
```

**The Problem:**
- Loads **ALL pending domains** and **ALL orders with pending domains** into memory
- Then does pagination in JavaScript (not in MongoDB)
- If you have 1,000 pending domains, it loads all 1,000 every time

**Memory Impact:** Can easily use 50-200MB per request

---

### 3. **Admin Payments Route - Excessive Data Fetching**

```typescript
// Fetch 5x the requested limit or minimum 25
const fetchLimit = Math.max(limit * 5, 25);

// Then filters in JavaScript
const allDomainPayments = RazorpayPaymentsService.filterDomainPayments(
  razorpayPayments.items
);
```

**Problem:** Fetches way more data than needed, then filters client-side.

---

### 4. **No Connection Pooling Limits**

**In `lib/mongodb.ts`:**
```typescript
const opts = {
  bufferCommands: false,
};
```

**Missing critical options:**
- `maxPoolSize`: No limit on database connections
- `minPoolSize`: No minimum pool maintained
- `maxIdleTimeMS`: Connections never close
- `serverSelectionTimeoutMS`: No timeout

**Result:** Under load, unlimited connections can be created, each consuming memory.

---

### 5. **Model Recompilation on Every HMR (Hot Module Reload)**

While your models use proper caching:
```typescript
export default mongoose.models.PendingDomain ||
  mongoose.model<IPendingDomain>("PendingDomain", PendingDomainSchema);
```

**However:** During development with HMR (Hot Module Replacement):
- Modules are reloaded frequently
- Schema definitions accumulate
- Index definitions multiply
- Memory slowly grows

---

### 6. **Unhandled Promise Rejections & Server Actions Errors**

**From error log (Lines 3-26):**
```
Missing `origin` header from a forwarded Server Actions request.
Error: Failed to find Server Action "null"
```

**What happens:**
- These errors create stack traces
- Stack traces are stored in memory
- If errors repeat rapidly (which they do in your logs), memory fills up
- Your log shows this error **repeating hundreds of times**

---

### 7. **No Memory Limits or Garbage Collection Tuning**

Your PM2 config didn't have:
- Memory restart limits
- Node.js GC (Garbage Collection) optimization flags
- Proper error handling to prevent error accumulation

---

## üéØ The Perfect Storm Scenario

Here's what happens during a crash:

```
1. Server starts (100MB RAM)
   ‚Üì
2. Admin checks pending domains
   ‚Üí Loads ALL pending domains (50MB)
   ‚Üí Loads ALL orders (30MB)
   ‚Üì
3. Schema index warning repeats
   ‚Üí Accumulating duplicate definitions (10MB)
   ‚Üì
4. Server Actions errors start
   ‚Üí Stack traces pile up (20MB)
   ‚Üì
5. Multiple API calls happen simultaneously
   ‚Üí Each loads 100 orders (100MB)
   ‚Üí Each loads all pending domains (50MB)
   ‚Üì
6. Memory usage: 360MB and growing
   ‚Üì
7. Garbage collection can't keep up
   ‚Üì
8. Memory reaches system limit
   ‚Üì
9. OOM Killer strikes: "Killed"
   ‚Üì
10. Server tries to restart
    ‚Üí But build files are gone
    ‚Üí Port is still in use
    ‚Üí Crash loop begins!
```

---

## ‚úÖ Solutions (Immediate + Long-term)

### Immediate Fixes (Already provided):

1. ‚úÖ **Run the fix script** - Breaks the crash loop
2. ‚úÖ **Use ecosystem.config.js** - Adds memory limits (1GB restart)
3. ‚úÖ **Add restart delays** - Prevents rapid restart loops

### Code Fixes Needed:

#### 1. Fix PendingDomain Schema (Remove Duplicate Index)

```typescript
// File: models/PendingDomain.ts
// Line 38 - Keep this
domainName: {
  type: String,
  required: [true, "Domain name is required"],
  trim: true,
  lowercase: true,
  unique: true, // This creates domainName_1 index automatically
},

// Lines 144-147 - ADD COMPOUND INDEX ONLY (not single field)
// DON'T create another domainName index!
PendingDomainSchema.index({ userId: 1, status: 1 });
PendingDomainSchema.index({ orderId: 1 });
PendingDomainSchema.index({ status: 1, createdAt: -1 });
PendingDomainSchema.index({ lastVerifiedAt: 1 });
```

#### 2. Add Pagination to Pending Domains API

```typescript
// File: app/api/admin/pending-domains/route.ts
// BEFORE: Loads everything
const pendingDomainsFromCollection = await PendingDomain.find(filters)
  .sort(sortOptions)
  .populate("userId", "firstName lastName email", User);

// AFTER: Add pagination at DB level
const skip = (page - 1) * limit;
const pendingDomainsFromCollection = await PendingDomain.find(filters)
  .sort(sortOptions)
  .limit(limit)
  .skip(skip)
  .populate("userId", "firstName lastName email", User);

// Also get total count
const total = await PendingDomain.countDocuments(filters);
```

#### 3. Fix MongoDB Connection Options

```typescript
// File: lib/mongodb.ts
const opts = {
  bufferCommands: false,
  maxPoolSize: 10,           // Max 10 connections
  minPoolSize: 2,            // Keep 2 connections ready
  maxIdleTimeMS: 30000,      // Close idle connections after 30s
  serverSelectionTimeoutMS: 5000,  // 5s timeout
  socketTimeoutMS: 45000,    // 45s socket timeout
};
```

#### 4. Add Request Deduplication for Heavy Queries

```typescript
// Create a simple cache for admin routes
const queryCache = new Map();
const CACHE_TTL = 30000; // 30 seconds

// In heavy routes:
const cacheKey = `pending-domains-${JSON.stringify(filters)}`;
const cached = queryCache.get(cacheKey);

if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
  return NextResponse.json(cached.data);
}

// ... do expensive query ...

queryCache.set(cacheKey, {
  data: result,
  timestamp: Date.now()
});
```

#### 5. Add Memory Monitoring

```typescript
// Add to your API routes
setInterval(() => {
  const usage = process.memoryUsage();
  if (usage.heapUsed > 500 * 1024 * 1024) { // 500MB
    console.warn('‚ö†Ô∏è High memory usage:', {
      heapUsed: `${Math.round(usage.heapUsed / 1024 / 1024)}MB`,
      heapTotal: `${Math.round(usage.heapTotal / 1024 / 1024)}MB`,
      rss: `${Math.round(usage.rss / 1024 / 1024)}MB`,
    });
    
    // Force garbage collection if available
    if (global.gc) {
      console.log('üóëÔ∏è Forcing garbage collection...');
      global.gc();
    }
  }
}, 60000); // Check every minute
```

---

## üìà Memory Usage Breakdown (Typical)

| Component | Memory Usage |
|-----------|-------------|
| Next.js Runtime | ~80-100MB |
| Database Connection Pool | ~20-30MB |
| Single Order Query (100 orders) | ~10-20MB |
| All Pending Domains Query | ~30-100MB |
| Admin Payments Query | ~20-50MB |
| Error Stack Traces (accumulated) | ~10-50MB |
| Schema Definitions (with duplicates) | ~5-20MB |
| **Total During Peak** | **175-370MB** |
| **+ Memory Leak Growth** | **+50MB/hour** |
| **= Crisis Point** | **500MB-1GB** |

---

## üéì Why "Sometimes It Works"

1. **Light Load Times**: Few users, small queries ‚Üí memory stays under 200MB ‚úÖ
2. **Heavy Load Times**: Admin dashboard + multiple users ‚Üí memory spikes to 500MB+ ‚ùå
3. **Accumulated Leaks**: After running for hours, small leaks become big problems
4. **GC Timing**: If garbage collection runs at the right time, memory is freed ‚úÖ
5. **Request Patterns**: If multiple heavy requests hit simultaneously ‚Üí OOM ‚ùå

---

## üöÄ Action Plan

### Immediate (Do Now):
1. ‚úÖ Run the fix script
2. ‚úÖ Start with ecosystem.config.js
3. ‚úÖ Monitor with `pm2 monit`

### Short-term (This Week):
1. Fix PendingDomain schema (remove duplicate index)
2. Add MongoDB connection pool limits
3. Add pagination to pending domains API
4. Add memory monitoring

### Long-term (This Month):
1. Implement query caching for heavy operations
2. Add proper error handling to prevent stack trace accumulation
3. Optimize database queries
4. Consider Redis for caching
5. Set up proper monitoring (DataDog, New Relic, etc.)

---

## üí° Quick Wins (Immediate Impact):

1. **Add this to package.json scripts:**
```json
"start": "NODE_OPTIONS='--max-old-space-size=1024' next start"
```
This limits Node.js to 1GB RAM and forces more aggressive garbage collection.

2. **Add this to ecosystem.config.js:**
```javascript
node_args: '--max-old-space-size=1024 --expose-gc'
```

3. **Clean up old PM2 logs:**
```bash
pm2 flush  # Clears all logs
```

---

## üéØ Expected Results After Fixes:

- **Current**: Crashes every 2-24 hours
- **After immediate fixes**: Stable for days/weeks with restarts at 1GB
- **After code fixes**: Stable indefinitely with memory ~150-300MB
- **After optimization**: Peak memory ~100-200MB

---

**Bottom Line**: Your memory issue is a combination of:
1. ‚ùå Unbounded queries loading too much data
2. ‚ùå Duplicate schema index creating memory leaks
3. ‚ùå No connection pool limits
4. ‚ùå Accumulated error stack traces
5. ‚ùå No memory monitoring or limits

**The fix script solves the crisis, but code changes prevent future crises.**

